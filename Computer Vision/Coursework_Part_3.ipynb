{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM2M8MD2+trf85a+OTWCbys"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Implement CNN with Early Stopping on CIFAR-10"],"metadata":{"id":"uvbbKSQ6mJMD"}},{"cell_type":"markdown","source":["**Import Pytorch Modules and Functions**"],"metadata":{"id":"84rycNzQmL4C"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"1XTvj2wMmAIm"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, random_split, Subset\n","from torchvision import datasets, transforms\n","import numpy as np\n","import copy\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","source":["**Check GPU Availability**"],"metadata":{"id":"LBMLoT9pmNbA"}},{"cell_type":"code","source":["# Check if GPU is available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")"],"metadata":{"id":"NQ2dXR5tmP76"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Training Configuration and Hyperparameters**\n"],"metadata":{"id":"XOBZdO9gmRMJ"}},{"cell_type":"code","source":["batch_size = 128\n","initial_lr = 0.0005\n","lr_decay_factor = 0.1\n","lr_patience = 7\n","max_epochs = 75\n","patience = 15\n","weight_decay = 1e-4"],"metadata":{"id":"G1sJBwnqmSpw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Dataset Loading and Preprocessing**\n"],"metadata":{"id":"thgiPHzumUYb"}},{"cell_type":"code","source":["# Load the dataset without transforms initially\n","full_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=None)\n","\n","means = full_dataset.data.mean(axis=(0,1,2)) / 255\n","stds = full_dataset.data.std(axis=(0,1,2)) / 255\n","\n","# Define transformations\n","train_transform = transforms.Compose([\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomCrop(32, padding=4),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=means, std=stds)\n","])\n","\n","val_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=means, std=stds)\n","])\n","\n","\n","# Calculate split sizes\n","val_size = int(0.1 * len(full_dataset))\n","train_size = len(full_dataset) - val_size\n","\n","# Perform random split\n","train_indices, val_indices = random_split(range(len(full_dataset)), [train_size, val_size])\n","\n","# Create Subsets with proper transforms\n","train_dataset = Subset(full_dataset, train_indices)\n","train_dataset.dataset.transform = train_transform\n","\n","val_dataset = Subset(full_dataset, val_indices)\n","val_dataset.dataset.transform = val_transform\n","\n","# Create data loaders\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n"],"metadata":{"id":"pvbNpsq4mWcD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**VGG-16 Design**\n"],"metadata":{"id":"2Dy_hksMmYgl"}},{"cell_type":"code","source":["class VGG16(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        # Block 1: input channels=3, output channels=64\n","        self.conv1 = nn.Sequential(\n","            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2)\n","        )\n","\n","        # Block 2: input channels=64, output channels=128\n","        self.conv2 = nn.Sequential(\n","            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2)\n","        )\n","\n","        # Block 3: input channels=128, output channels=256\n","        self.conv3 = nn.Sequential(\n","            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2)\n","        )\n","\n","        # Block 4: input channels=256, output channels=512\n","        self.conv4 = nn.Sequential(\n","            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2)\n","        )\n","\n","        # Block 5: input channels=512, output channels=512\n","        self.conv5 = nn.Sequential(\n","            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2)\n","        )\n","\n","        # Fully connected layers\n","        self.fc = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Linear(512 * 1 * 1, 4096),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(p=0.5),\n","            nn.Linear(4096, 4096),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(p=0.5),\n","            nn.Linear(4096, 10)  # 10 classes for CIFAR-10\n","        )\n","\n","        # Initialize weights according to VGG paper\n","        self._initialize_weights()\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.conv2(x)\n","        x = self.conv3(x)\n","        x = self.conv4(x)\n","        x = self.conv5(x)\n","        x = self.fc(x)\n","        return x\n","\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.normal_(m.weight, mean=0, std=0.01)\n","                if m.bias is not None:\n","                    nn.init.constant_(m.bias, 0)\n","            elif isinstance(m, nn.Linear):\n","                nn.init.normal_(m.weight, mean=0, std=0.01)\n","                nn.init.constant_(m.bias, 0)\n","\n","model = VGG16().to(device)\n"],"metadata":{"id":"hmSmEDFVmbNI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Training Functions**\n"],"metadata":{"id":"iIbMcFXEmc0j"}},{"cell_type":"code","source":["def correct(output, target):\n","    pred = output.argmax(1)\n","    prediction = (pred == target).type(torch.float)\n","    return prediction.sum().item()"],"metadata":{"id":"4XE3diHxmdq4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train(data_loader, model, lossfun, optimizer):\n","    model.train()\n","\n","    num_batches = len(data_loader)\n","    total_loss = 0\n","    total_correct = 0\n","\n","    for data, target in data_loader:\n","        data, target = data.to(device), target.to(device)\n","\n","        # Forward pass\n","        optimizer.zero_grad()\n","\n","        output = model(data)\n","\n","        loss = lossfun(output, target)\n","        total_loss += loss.item()\n","\n","        total_correct += correct(output, target)\n","\n","        # Backward pass\n","        loss.backward()\n","        optimizer.step()\n","\n","\n","    avg_loss = total_loss / num_batches\n","    accuracy = 100. * total_correct / len(data_loader.dataset)\n","    return avg_loss, accuracy\n","\n"],"metadata":{"id":"b2kHuUuOmexf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def validate(data_loader, model, lossfun):\n","    model.eval()\n","    total_loss = 0\n","    total_correct = 0\n","\n","    with torch.no_grad():\n","        for data, target in data_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            total_loss += lossfun(output, target).item()\n","            total_correct += correct(output, target)\n","\n","    avg_loss = total_loss / len(data_loader)\n","    accuracy = 100. * total_correct / len(data_loader.dataset)\n","    return avg_loss, accuracy"],"metadata":{"id":"CpiSbGDXmgO9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def run_training(model, train_loader, val_loader, lossfun, optimizer, scheduler, best_model_filename):\n","    history = []\n","    best_val_loss = float('inf')\n","    no_improve = 0\n","\n","    for epoch in range(max_epochs):\n","        # Training phase\n","        train_loss, train_acc = train(train_loader, model, lossfun, optimizer)\n","\n","        # Validation phase\n","        val_loss, val_acc = validate(val_loader, model, lossfun)\n","\n","        # Store history\n","        history.append([train_loss, val_loss, train_acc, val_acc])\n","\n","        print(f'Epoch: {epoch+1}')\n","        print(f'Training Loss: {train_loss:.6f}, Training Accuracy: {train_acc:.2f}%')\n","        print(f'Val Loss: {val_loss:.6f}, Val Accuracy: {val_acc:.2f}%\\n')\n","\n","        # Step the scheduler with the validation loss\n","        scheduler.step(val_loss)\n","\n","        # Early stopping check\n","        if val_loss < best_val_loss:\n","            best_val_loss = val_loss\n","            torch.save(model.state_dict(), best_model_filename)\n","            no_improve = 0\n","        else:\n","            no_improve += 1\n","            if no_improve >= patience:\n","                print('Early stopping triggered!')\n","                break\n","\n","    return history"],"metadata":{"id":"fVLDrgiImhkk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Training Setup**"],"metadata":{"id":"Ah51Gq-AmkVK"}},{"cell_type":"code","source":["lossfun = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=initial_lr, weight_decay=weight_decay)\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n","    optimizer, mode='min', factor=lr_decay_factor, patience=lr_patience)\n","best_model_filename = 'best_model.pt'\n","history = run_training(model, train_loader, val_loader, lossfun, optimizer, scheduler, best_model_filename)"],"metadata":{"id":"vRJqMhaQmlkD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Best Performing Model Statistics**"],"metadata":{"id":"sypoYqVrmojx"}},{"cell_type":"code","source":["# Load the best performing model weights\n","model.load_state_dict(torch.load('best_model.pt', weights_only=True))\n","\n","# Evaluate the best model on the training set\n","train_loss, train_acc = validate(train_loader, model, lossfun)\n","print(f\"Best Model Training Loss: {train_loss:.6f}, Training Accuracy: {train_acc:.2f}%\")\n","\n","# Evaluate the best model on the validation set\n","val_loss, val_acc = validate(val_loader, model, lossfun)\n","print(f\"Best Model Validation Loss: {val_loss:.6f}, Validation Accuracy: {val_acc:.2f}%\")"],"metadata":{"id":"gqqGZuAJmp2O"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Plot Training Results**\n"],"metadata":{"id":"B7tfEmUZmsFK"}},{"cell_type":"code","source":["history = np.array(history)\n","\n","# Plot Loss\n","plt.figure(figsize=(6, 4))\n","plt.plot(history[:, 0], label='Train Loss')\n","plt.plot(history[:, 1], label='Val Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Training and Validation Loss')\n","plt.legend()\n","plt.show()\n","\n","# Plot Accuracy\n","plt.figure(figsize=(6, 4))\n","plt.plot(history[:, 2], label='Train Acc')\n","plt.plot(history[:, 3], label='Val Acc')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy (%)')\n","plt.title('Training and Validation Accuracy')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"A3VW4OWNmtSm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2. Compare CNN With and Without Batch Normalization"],"metadata":{"id":"95vtBI7Dmvje"}},{"cell_type":"markdown","source":["**VGG-16 With Batch Normalization Design**"],"metadata":{"id":"ffv3Z1smmxqH"}},{"cell_type":"code","source":["class VGG16WithBatchNorm(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        # Block 1: input channels=3, output channels=64\n","        self.conv1 = nn.Sequential(\n","            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2)\n","        )\n","\n","        # Block 2: input channels=64, output channels=128\n","        self.conv2 = nn.Sequential(\n","            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2)\n","        )\n","\n","        # Block 3: input channels=128, output channels=256\n","        self.conv3 = nn.Sequential(\n","            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2)\n","        )\n","\n","        # Block 4: input channels=256, output channels=512\n","        self.conv4 = nn.Sequential(\n","            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(512),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(512),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(512),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2)\n","        )\n","\n","        # Block 5: input channels=512, output channels=512\n","        self.conv5 = nn.Sequential(\n","            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(512),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(512),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(512),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2)\n","        )\n","\n","        # Fully connected layers\n","        self.fc = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Linear(512 * 1 * 1, 4096),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(p=0.5),\n","            nn.Linear(4096, 4096),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(p=0.5),\n","            nn.Linear(4096, 10)  # 10 classes for CIFAR-10\n","        )\n","\n","        # Initialize weights according to VGG paper\n","        self._initialize_weights()\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.conv2(x)\n","        x = self.conv3(x)\n","        x = self.conv4(x)\n","        x = self.conv5(x)\n","        x = self.fc(x)\n","        return x\n","\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                # Initialize conv layers with small random weights\n","                nn.init.normal_(m.weight, mean=0, std=0.01)\n","                if m.bias is not None:\n","                    nn.init.constant_(m.bias, 0)\n","            elif isinstance(m, nn.Linear):\n","                nn.init.normal_(m.weight, mean=0, std=0.01)\n","                nn.init.constant_(m.bias, 0)\n","\n","model_bn = VGG16WithBatchNorm().to(device)\n"],"metadata":{"id":"DckIi2ePmz5-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Training Setup**"],"metadata":{"id":"n7_wuvO9m1Xp"}},{"cell_type":"code","source":["initial_lr = 0.001\n","\n","optimizer_bn = optim.Adam(model_bn.parameters(), lr=initial_lr, weight_decay=weight_decay)\n","scheduler_bn = optim.lr_scheduler.ReduceLROnPlateau(optimizer_bn, mode='min',\n","                                                  factor=lr_decay_factor,\n","                                                  patience=lr_patience)\n","model_filename = 'best_model_bn.pt'\n","\n","history_bn = run_training(model_bn, train_loader, val_loader, lossfun, optimizer_bn, scheduler_bn, model_filename)"],"metadata":{"id":"ZeV8SsQVm3EE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Best Performing Model Statistics**"],"metadata":{"id":"YiNCxwvtm5CC"}},{"cell_type":"code","source":["# Load the best performing model weights\n","model_bn.load_state_dict(torch.load('best_model_bn.pt', weights_only=True))\n","\n","# Validate the best model on the training set\n","train_loss, train_acc = validate(train_loader, model_bn, lossfun)\n","print(f\"Best Model Training Loss: {train_loss:.6f}, Training Accuracy: {train_acc:.2f}%\")\n","\n","# Validate the best model on the validation set\n","val_loss, val_acc = validate(val_loader, model_bn, lossfun)\n","print(f\"Best Model Validation Loss: {val_loss:.6f}, Validation Accuracy: {val_acc:.2f}%\")"],"metadata":{"id":"FhpO9NFim6v9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Plot Training Results With and Without Batch Normalization**"],"metadata":{"id":"wtxVzU3ym8jZ"}},{"cell_type":"code","source":["# Plot comparison between models with and without batch normalization\n","history_bn = np.array(history_bn)\n","\n","plt.figure(figsize=(12, 5))\n","plt.subplot(1, 2, 1)\n","plt.plot(history[:, 0], label='Train Loss (without BN)')\n","plt.plot(history[:, 1], label='Val Loss (without BN)')\n","plt.plot(history_bn[:, 0], label='Train Loss (with BN)')\n","plt.plot(history_bn[:, 1], label='Val Loss (with BN)')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Training and Validation Loss Comparison')\n","plt.legend()\n","plt.grid(True)\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"QWpllP8wm963"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3. Visualize Convolutional Features"],"metadata":{"id":"-JW3SwWKnCjs"}},{"cell_type":"markdown","source":["**Visualization Functions**"],"metadata":{"id":"EnvgaxWSnEhJ"}},{"cell_type":"code","source":["def show_filters(model, layer_name):\n","    # Get the weights from the first Conv2d layer in the Sequential block\n","    if layer_name == 'conv1':\n","        weights = model.conv1[0].weight\n","        n_filters = 16\n","        grid_size = (2, 8)\n","    else:\n","        weights = getattr(model, layer_name)[0].weight\n","        n_filters = 8  # Show subset of filters for deeper layers\n","        grid_size = (1, 8)\n","\n","    weights = weights.cpu().detach()\n","    weights_min, weights_max = weights.min(), weights.max()\n","    weights = (weights - weights_min) / (weights_max - weights_min)\n","\n","    plt.figure(figsize=(20, 10 if layer_name == 'conv1' else 5))\n","    plt.suptitle(f'{layer_name} Convolutional Filters', fontsize=16)\n","\n","    for i in range(n_filters):\n","        plt.subplot(grid_size[0], grid_size[1], i+1)\n","        if layer_name == 'conv1':\n","            plt.imshow(weights[i].permute(1, 2, 0))  # RGB channels for conv1\n","        else:\n","            plt.imshow(weights[i, 0], cmap='viridis')\n","        plt.axis('off')\n","    plt.show()"],"metadata":{"id":"dTouiby_nFuF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def show_image_filters(filters, layer_name, image_idx):\n","    n_filters = 8\n","    plt.figure(figsize=(20, 5))\n","    plt.suptitle(f'{layer_name} Convolutional Filters for Test Image {image_idx+1}', fontsize=16)\n","\n","    for i in range(n_filters):\n","        plt.subplot(1, 8, i+1)\n","        image_filter = features[image_idx, i].cpu().numpy()\n","        plt.imshow(image_filter, cmap='viridis')\n","        plt.axis('off')\n","    plt.show()"],"metadata":{"id":"-cZVUaJ4nGR_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def show_test_image(image, idx):\n","    plt.figure(figsize=(5, 5))\n","    img = image.cpu().numpy().transpose(1, 2, 0)\n","    # Denormalize the image\n","    img = img * np.array(stds) + np.array(means)\n","    img = np.clip(img, 0, 1)\n","    plt.imshow(img)\n","    plt.title(f'Test Image {idx+1}', fontsize=14)\n","    plt.axis('off')\n","    plt.show()"],"metadata":{"id":"_RecxgV0nIkF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Visualization Setup**"],"metadata":{"id":"V0SwxzJRnLc1"}},{"cell_type":"code","source":["convolutional_layers = ['conv1', 'conv2', 'conv3', 'conv4', 'conv5']\n","\n","# Get test images\n","test_images, test_labels = next(iter(val_loader))\n","num_images = 3\n","test_batch = test_images[:num_images].to(device)\n","\n","# Dictionary to store activations\n","activations = {}\n","\n","# Hook function\n","def get_activation(name):\n","    def hook(model, input, output):\n","        activations[name] = output.detach()\n","    return hook\n","\n","# Register hooks for each convolution block\n","hooks = []\n","hooks.append(model_bn.conv1[0].register_forward_hook(get_activation('conv1')))\n","hooks.append(model_bn.conv2[0].register_forward_hook(get_activation('conv2')))\n","hooks.append(model_bn.conv3[0].register_forward_hook(get_activation('conv3')))\n","hooks.append(model_bn.conv4[0].register_forward_hook(get_activation('conv4')))\n","hooks.append(model_bn.conv5[0].register_forward_hook(get_activation('conv5')))\n","\n","# Forward pass with test images\n","model_bn.eval()\n","with torch.no_grad():\n","    model_bn(test_batch)"],"metadata":{"id":"Mnb_-NiNnM4l"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Convolutional Filters Visualization**"],"metadata":{"id":"d5LJId4RnNgl"}},{"cell_type":"code","source":["# Visualize raw convolutional filters\n","print(\"\\nConvolutional Filters\")\n","for layer_name in convolutional_layers:\n","    print(f\"\\n{layer_name} Filters:\")\n","    show_filters(model_bn, layer_name)\n","\n","# Show convolutional features for test images\n","print(\"\\nConvolutional Filters After Using Test Images\")\n","for i in range(num_images):\n","    print(f\"\\nAnalyzing Test Image {i+1}\")\n","    show_test_image(test_images[i], i)\n","\n","    for layer_name in convolutional_layers:\n","        print(f\"\\n{layer_name} convolutional filters:\")\n","        show_image_filters(activations[layer_name], layer_name, i)\n","\n","# Remove hooks\n","for hook in hooks:\n","    hook.remove()"],"metadata":{"id":"j7nplkC-nPoG"},"execution_count":null,"outputs":[]}]}